{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data_dantri_chungkhoan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.describe()\n",
    "\n",
    "data.drop_duplicates(subset=[\"content\"],inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong Tiếng Anh có rất nhiều từ nối và được sử dụng rất thường xuyên như \"and\", \"the\" và \"a\". Khi thực hiện việc thống kê trên văn bản, những từ này sẽ mang lại rất nhiều nhiễu vì chúng xuất hiện thường xuyên hơn các từ khác. Một số pineline về NLP sẽ gắn cờ chúng là các từ dừng (stop words) - nghĩa là các từ mà bạn có thể sẽ muốn lọc ra trước khi thực hiện bất kỳ các phân tích thống kê nào. Tương tự với Tiếng Việt cũng có rất nhiều stop words, chúng ta cần phải loại bỏ chúng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 1942\n",
      "First 10 stopwords: ['a lô', 'a ha', 'ai', 'ai ai', 'ai nấy', 'ai đó', 'alô', 'amen', 'anh', 'anh ấy']\n"
     ]
    }
   ],
   "source": [
    "# Đọc tệp vietnamesestopword.txt và lưu các từ dừng vào một danh sách\n",
    "stopwords = []\n",
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "print(f'Number of stopwords: {len(stopwords)}')\n",
    "print(f'First 10 stopwords: {stopwords[:10]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta phân tách dữ liệu văn bản của mình thành đơn vị nhỏ nhất được gọi là \"tokens\" hoặc \"words\". Việc phân tích các đoạn văn dài khá khó khăn nên trước tiên chúng ta tách các đoạn văn thành các dòng riêng biệt sau đó các dòng tách thành các từ và xóa stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_para(content):\n",
    "    \"\"\"Làm sạch văn bản bằng cách loại bỏ dấu câu, chuyển đổi thành chữ thường và loại bỏ stopwords.\"\"\"\n",
    "    # Kiểm tra nếu van_ban không phải là chuỗi, thì chuyển thành chuỗi\n",
    "    if not isinstance(content, str):\n",
    "        content = ' '.join(content)\n",
    "    # Loại bỏ dấu câu\n",
    "    content = re.sub(r'[^\\w\\s]', '', content)\n",
    "    # Chuyển đổi thành chữ thường\n",
    "    content = content.lower()\n",
    "    # Loại bỏ stopwords\n",
    "    tu_vung = content.split()\n",
    "    tu_vung_sach = [tu for tu in tu_vung if tu not in stopwords]\n",
    "    return ' '.join(tu_vung_sach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       content_cleaned\n",
      "0    bloomberg billionaires index jensen huang ceo ...\n",
      "1    giao dịch giằng co phiên phiên chiều 245 áp lự...\n",
      "2    kết phiên giao dịch 225 mỹ cổ phiếu nvidia 05 ...\n",
      "3    rung lắc phiên tiếp tục chỉnh đầu phiên chiều ...\n",
      "4    đỗ quang vinh phó chủ tịch hội đồng quản trị n...\n",
      "..                                                 ...\n",
      "569  thị trường giao dịch căng thẳng mệt mỏi hầu đầ...\n",
      "570  công ty chứng khoán agribank agirseco vnindex ...\n",
      "571  phiên hôm 73 vnindex tiếp tục diễn biến giá tí...\n",
      "572  mặc lực chiều dâng đà thu hẹp yếu dần phiên nh...\n",
      "573  công ty chứng khoán agribank agriseco vnindex ...\n",
      "\n",
      "[574 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "data['content_cleaned'] = data['content'].apply(clean_para)\n",
    "print(data[['content_cleaned']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xây dựng mô hình LSA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Chia dữ liệu thành tập huấn luyện, xác thực và tập kiểm tra 70-15-15\n",
    "text_train, text_val_test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "text_val, text_test = train_test_split(text_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Yến Vy\\Jupyternotebook\\.conda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "d:\\Yến Vy\\Jupyternotebook\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Yến Vy\\Jupyternotebook\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 765, in _score\n",
      "    scores = scorer(estimator, X_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "d:\\Yến Vy\\Jupyternotebook\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)),\n",
       "                                       (&#x27;svd&#x27;, TruncatedSVD())]),\n",
       "             param_grid={&#x27;svd__n_components&#x27;: [2, 5, 10, 20],\n",
       "                         &#x27;tfidf__max_df&#x27;: [0.8, 0.9], &#x27;tfidf__min_df&#x27;: [1, 2]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)),\n",
       "                                       (&#x27;svd&#x27;, TruncatedSVD())]),\n",
       "             param_grid={&#x27;svd__n_components&#x27;: [2, 5, 10, 20],\n",
       "                         &#x27;tfidf__max_df&#x27;: [0.8, 0.9], &#x27;tfidf__min_df&#x27;: [1, 2]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)),\n",
       "                (&#x27;svd&#x27;, TruncatedSVD())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(tokenizer=<function clean_para at 0x000001F96B07D760>)),\n",
       "                                       ('svd', TruncatedSVD())]),\n",
       "             param_grid={'svd__n_components': [2, 5, 10, 20],\n",
       "                         'tfidf__max_df': [0.8, 0.9], 'tfidf__min_df': [1, 2]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Xây dựng pipeline và tìm kiếm tham số tốt nhất\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=clean_para)),\n",
    "    ('svd', TruncatedSVD())\n",
    "])\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.8, 0.9],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'svd__n_components': [2, 5, 10, 20]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(text_train['content_cleaned'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8,\n",
       "                                 tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)),\n",
       "                (&#x27;svd&#x27;, TruncatedSVD())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.8,\n",
       "                                 tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)),\n",
       "                (&#x27;svd&#x27;, TruncatedSVD())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8,\n",
       "                tokenizer=&lt;function clean_para at 0x000001F96B07D760&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8,\n",
       "                                 tokenizer=<function clean_para at 0x000001F96B07D760>)),\n",
       "                ('svd', TruncatedSVD())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện mô hình với tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_df=best_params['tfidf__max_df'], min_df=best_params['tfidf__min_df'], tokenizer=clean_para)),\n",
    "    ('svd', TruncatedSVD(n_components=best_params['svd__n_components']))\n",
    "])\n",
    "model.fit(text_train['content_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tóm tắt văn bản***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def summarize_text(text, model, train_data): \n",
    "    text_vector = model.transform([text])\n",
    "    \n",
    "    train_vectors = model.named_steps['tfidf'].transform(train_data['content_cleaned'])\n",
    "    train_lsa = model.named_steps['svd'].transform(train_vectors) \n",
    "    \n",
    "    # Đảm bảo rằng text_lsa và train_lsa có cùng số lượng thành phần\n",
    "    n_components = min(text_vector.shape[1], train_lsa.shape[1])\n",
    "    text_lsa = text_vector[:, :n_components]\n",
    "    train_lsa = train_lsa[:, :n_components]\n",
    "\n",
    "    # Tính toán độ tương đồng cosine giữa các câu và văn bản gốc\n",
    "    similarities = cosine_similarity(text_lsa, train_lsa)[0]\n",
    "    \n",
    "    # Xử lý trường hợp không có độ tương đồng\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    if sentences and similarities.size > 0:\n",
    "        top_sentence = similarities.argsort()[-1] \n",
    "        # Trả về câu đầu tiên nếu chỉ mục không hợp lệ\n",
    "        return sentences[top_sentence] if top_sentence < len(sentences) else sentences[0] \n",
    "    else:\n",
    "        return \"No similar sentences found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       content_cleaned  \\\n",
      "388  pha bẻ lái gay cấn đầu tư đau tim diễn phiên g...   \n",
      "208  phiên giao dịch hôm đầu tư yếu tim đi khoản rà...   \n",
      "90   10 cổ phiếu hpg tập đoàn hòa phát bật 31 29900...   \n",
      "209  2811 trang web công ty cổ vận tải xếp dỡ hải a...   \n",
      "9    thị trường diễn biến tích cực phiên 165 khoản ...   \n",
      "..                                                 ...   \n",
      "11   phiên giao dịch chiều 145 giằng co trạng thái ...   \n",
      "380  công ty chứng khoán dnse kết thúc phiên giao d...   \n",
      "532  phiên 293 85 mã giá hose 1 mã trần mã 251 mã 7...   \n",
      "341  công ty chứng khoán dnse kết phiên 168 vnindex...   \n",
      "77   ủy ban chứng khoán ubcknn thông báo kiến đơn v...   \n",
      "\n",
      "                                               summary  \n",
      "388  pha bẻ lái gay cấn đầu tư đau tim diễn phiên g...  \n",
      "208  phiên giao dịch hôm đầu tư yếu tim đi khoản rà...  \n",
      "90   10 cổ phiếu hpg tập đoàn hòa phát bật 31 29900...  \n",
      "209  2811 trang web công ty cổ vận tải xếp dỡ hải a...  \n",
      "9    thị trường diễn biến tích cực phiên 165 khoản ...  \n",
      "..                                                 ...  \n",
      "11   phiên giao dịch chiều 145 giằng co trạng thái ...  \n",
      "380  công ty chứng khoán dnse kết thúc phiên giao d...  \n",
      "532  phiên 293 85 mã giá hose 1 mã trần mã 251 mã 7...  \n",
      "341  công ty chứng khoán dnse kết phiên 168 vnindex...  \n",
      "77   ủy ban chứng khoán ubcknn thông báo kiến đơn v...  \n",
      "\n",
      "[86 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng hàm summarize_text để tạo tóm tắt cho các đoạn văn trong tập dữ liệu kiểm định\n",
    "text_val['summary'] = text_val['content_cleaned'].apply(lambda x: summarize_text(x, model, text_train)) \n",
    "print(text_val[['content_cleaned', 'summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       content_cleaned  \\\n",
      "348  vingroup phát thông cáo vinfast black spade ac...   \n",
      "369  trạng thái giằng co căng thẳng đầu phiên đầu t...   \n",
      "84   thị trường giằng co xu hướng lan rộng thời 11h...   \n",
      "79   14 trang chủ công ty chứng khoán vndirect phát...   \n",
      "68   phiên giao dịch 263 thị trường cổ phiếu ngành ...   \n",
      "..                                                 ...   \n",
      "436  vnindex tiếp tục nỗ lực công phá mốc cản 1100 ...   \n",
      "76   thị trường chứng khoán phiên 213 tiếp tục hồi ...   \n",
      "311  cửa phiên 19 sàn chứng khoán nasdaq cổ phiếu v...   \n",
      "371  công ty chứng khoán dnse kết thúc phiên giao d...   \n",
      "184  vận động tranh cử thành phố reno mỹ hôm 1712 c...   \n",
      "\n",
      "                                               summary  \n",
      "348  vingroup phát thông cáo vinfast black spade ac...  \n",
      "369  trạng thái giằng co căng thẳng đầu phiên đầu t...  \n",
      "84   thị trường giằng co xu hướng lan rộng thời 11h...  \n",
      "79   14 trang chủ công ty chứng khoán vndirect phát...  \n",
      "68   phiên giao dịch 263 thị trường cổ phiếu ngành ...  \n",
      "..                                                 ...  \n",
      "436  vnindex tiếp tục nỗ lực công phá mốc cản 1100 ...  \n",
      "76   thị trường chứng khoán phiên 213 tiếp tục hồi ...  \n",
      "311  cửa phiên 19 sàn chứng khoán nasdaq cổ phiếu v...  \n",
      "371  công ty chứng khoán dnse kết thúc phiên giao d...  \n",
      "184  vận động tranh cử thành phố reno mỹ hôm 1712 c...  \n",
      "\n",
      "[87 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng hàm summarize_text để tạo tóm tắt cho các đoạn văn trong tập dữ liệu kiểm tra\n",
    "text_test['summary'] = text_test['content_cleaned'].apply(lambda x: summarize_text(x, model, text_train)) \n",
    "print(text_test[['content_cleaned', 'summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (0.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: absl-py in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from rouge-score) (1.26.3)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from nltk->rouge-score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from nltk->rouge-score) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from nltk->rouge-score) (4.66.4)\n",
      "Requirement already satisfied: colorama in d:\\yến vy\\jupyternotebook\\.conda\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores on Validation Set: {'rouge1': 0.9454221081585908, 'rouge2': 0.760826612633214, 'rougeL': 0.9421221138983994}\n",
      "ROUGE Scores on Test Set: {'rouge1': 0.9481295538211897, 'rouge2': 0.7657239537538871, 'rougeL': 0.9442525656683922}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def evaluate_summaries(true_summaries, generated_summaries):\n",
    "    rouge1, rouge2, rougeL = 0, 0, 0\n",
    "    n = len(true_summaries)\n",
    "    for true, generated in zip(true_summaries, generated_summaries):\n",
    "        scores = scorer.score(true, generated)\n",
    "        rouge1 += scores['rouge1'].precision\n",
    "        rouge2 += scores['rouge2'].precision\n",
    "        rougeL += scores['rougeL'].precision\n",
    "    return {\n",
    "        'rouge1': rouge1 / n,\n",
    "        'rouge2': rouge2 / n,\n",
    "        'rougeL': rougeL / n\n",
    "    }\n",
    "\n",
    "#Đánh giá tập val và test\n",
    "evaluation_scores = evaluate_summaries(text_val['content'], text_val['summary'])\n",
    "print(f\"ROUGE Scores on Validation Set: {evaluation_scores}\")\n",
    "\n",
    "evaluation_scores_test = evaluate_summaries(text_test['content'], text_test['summary'])\n",
    "print(f\"ROUGE Scores on Test Set: {evaluation_scores_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
